{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Required Libraries\n",
    "Import necessary libraries such as argparse, math, collections, numpy, Metashape, os, sys, exifread, importlib, csv, and Path from pathlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'upd_micasense_pos' from 'c:\\\\Users\\\\admin\\\\Documents\\\\Python Scripts\\\\drone_metashape\\\\upd_micasense_pos.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import math\n",
    "import collections\n",
    "import numpy as np\n",
    "import Metashape\n",
    "import os\n",
    "import sys\n",
    "import exifread\n",
    "from collections import defaultdict\n",
    "from upd_micasense_pos import ret_micasense_pos\n",
    "import importlib\n",
    "import upd_micasense_pos\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "importlib.reload(upd_micasense_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Constants and Global Variables\n",
    "Define constants and global variables used throughout the script, such as BASE_DIR, use_model, use_dem, GEOG_COORD, SOURCE_CRS, CONST_a, CONST_inv_f, CHUNK_RGB, CHUNK_MULTISPEC, IMG_QUAL_THRESHOLD, DICT_SMOOTH_STRENGTH, P1_GIMBAL1_OFFSET, and offset_dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Constants and Global Variables\n",
    "\n",
    "# Base directory for the project\n",
    "BASE_DIR = \"M:/working_package_2/2024_dronecampaign/01_data/dronetest/processing_test\"\n",
    "\n",
    "# Flags to decide whether to use model or DEM for orthomosaic\n",
    "use_model = False\n",
    "use_dem = True\n",
    "\n",
    "# Named tuple for geographic coordinates\n",
    "GEOG_COORD = collections.namedtuple('Geog_CS', ['lat_decdeg', 'lon_decdeg', 'elliph'])\n",
    "\n",
    "# Source coordinate reference system (CRS)\n",
    "SOURCE_CRS = Metashape.CoordinateSystem(\"EPSG::4326\")  # WGS84\n",
    "\n",
    "# Constants for WGS84 ellipsoid\n",
    "CONST_a = 6378137  # Semi major axis\n",
    "CONST_inv_f = 298.257223563  # Inverse flattening 1/f WGS84 ellipsoid\n",
    "\n",
    "# Chunk labels in Metashape\n",
    "CHUNK_RGB = \"rgb\"\n",
    "CHUNK_MULTISPEC = \"multispec\"\n",
    "\n",
    "# Image quality threshold\n",
    "IMG_QUAL_THRESHOLD = 0.7\n",
    "\n",
    "# Dictionary for smoothing strength values\n",
    "DICT_SMOOTH_STRENGTH = {'low': 50, 'medium': 100, 'high': 200}\n",
    "\n",
    "# Lever-arm offsets for different sensors on Matrice 300\n",
    "P1_GIMBAL1_OFFSET = (0.087, 0.0, 0.0)\n",
    "\n",
    "# Lever-arm offsets for MicaSense sensors\n",
    "offset_dict = defaultdict(dict)\n",
    "offset_dict['RedEdge-M']['Red'] = (-0.097, -0.03, -0.06)\n",
    "offset_dict['RedEdge-M']['Dual'] = (-0.097, 0.02, -0.08)\n",
    "offset_dict['RedEdge-P']['Red'] = (0, 0, 0)\n",
    "offset_dict['RedEdge-P']['Dual'] = (0, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Helper Functions\n",
    "Define helper functions used in the script, including `cartesian_to_geog`, `find_files`, and `copyBoundingBox`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Helper Functions\n",
    "\n",
    "def cartesian_to_geog(X, Y, Z):\n",
    "    \"\"\"\n",
    "    Convert Cartesian coordinates to geographic coordinates using WGS84 ellipsoid.\n",
    "    Return Lat, Lon, ellipsoidal height as a named tuple.\n",
    "    \"\"\"\n",
    "    f = 1 / CONST_inv_f\n",
    "    e_sq = 2 * f - f ** 2\n",
    "    p = math.sqrt(X ** 2 + Y ** 2)\n",
    "    r = math.sqrt(p ** 2 + Z ** 2)\n",
    "    mu = math.atan((Z / p) * (1 - f) + (e_sq * CONST_a) / r)\n",
    "\n",
    "    lat_top_line = Z * (1 - f) + e_sq * CONST_a * math.sin(mu) ** 3\n",
    "    lat_bottom_line = (1 - f) * (p - e_sq * CONST_a * math.cos(mu) ** 3)\n",
    "\n",
    "    lon = math.atan(Y / X)\n",
    "    lat = math.atan(lat_top_line / lat_bottom_line)\n",
    "\n",
    "    if lon < 0:\n",
    "        tmp_lon = lon + math.pi\n",
    "    else:\n",
    "        tmp_lon = lon\n",
    "\n",
    "    lon_dec_deg = (tmp_lon / math.pi) * 180\n",
    "    lat_dec_deg = (lat / math.pi) * 180\n",
    "\n",
    "    ellip_h = p * math.cos(lat) + Z * math.sin(lat) - CONST_a * math.sqrt(1 - e_sq * math.sin(lat) ** 2)\n",
    "\n",
    "    conv_coord = GEOG_COORD(lat_dec_deg, lon_dec_deg, ellip_h)\n",
    "\n",
    "    return conv_coord\n",
    "\n",
    "def find_files(folder, types):\n",
    "    \"\"\"\n",
    "    Find files of specified types in a folder.\n",
    "    \"\"\"\n",
    "    photo_list = list()\n",
    "    for dir, subdir, file in os.walk(folder):\n",
    "        for filename in file:\n",
    "            if filename.lower().endswith(types):\n",
    "                photo_list.append(os.path.join(dir, filename))\n",
    "    return photo_list\n",
    "\n",
    "def copyBoundingBox(from_chunk_label, to_chunk_labels):\n",
    "    \"\"\"\n",
    "    Copy bounding box from one chunk to others.\n",
    "    \"\"\"\n",
    "    print(\"Script started...\")\n",
    "\n",
    "    doc = Metashape.app.document()\n",
    "\n",
    "    from_chunk = None\n",
    "    for chunk in doc.chunks:\n",
    "        if chunk.label == from_chunk_label:\n",
    "            from_chunk = chunk\n",
    "            break\n",
    "\n",
    "    if not from_chunk:\n",
    "        print(f\"Chunk with label '{from_chunk_label}' not found.\")\n",
    "        return\n",
    "\n",
    "    to_chunks = []\n",
    "    for chunk in doc.chunks:\n",
    "        if chunk.label in to_chunk_labels:\n",
    "            to_chunks.append(chunk)\n",
    "\n",
    "    if not to_chunks:\n",
    "        print(\"No valid target chunks found.\")\n",
    "        return\n",
    "\n",
    "    print(\"Copying bounding box from chunk '\" + from_chunk.label + \"' to \" + str(len(to_chunks)) + \" chunks...\")\n",
    "\n",
    "    T0 = from_chunk.transform.matrix\n",
    "\n",
    "    region = from_chunk.region\n",
    "    R0 = region.rot\n",
    "    C0 = region.center\n",
    "    s0 = region.size\n",
    "\n",
    "    for chunk in to_chunks:\n",
    "        if chunk == from_chunk:\n",
    "            continue\n",
    "\n",
    "        T = chunk.transform.matrix.inv() * T0\n",
    "\n",
    "        R = Metashape.Matrix([[T[0, 0], T[0, 1], T[0, 2]],\n",
    "                              [T[1, 0], T[1, 1], T[1, 2]],\n",
    "                              [T[2, 0], T[2, 1], T[2, 2]]])\n",
    "\n",
    "        scale = R.row(0).norm()\n",
    "        R = R * (1 / scale)\n",
    "\n",
    "        new_region = Metashape.Region()\n",
    "        new_region.rot = R * R0\n",
    "        c = T.mulp(C0)\n",
    "        new_region.center = c\n",
    "        new_region.size = s0 * scale / 1.\n",
    "\n",
    "        chunk.region = new_region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Main Processing Functions\n",
    "Define the main processing functions `proc_rgb` and `proc_multispec` that handle the processing of RGB and multispectral images, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Main Processing Functions\n",
    "\n",
    "def proc_rgb():\n",
    "    \"\"\"\n",
    "    Process RGB images to create orthomosaic and 3D model.\n",
    "    \"\"\"\n",
    "    chunk = doc.findChunk(dict_chunks[CHUNK_RGB])\n",
    "    proj_file = doc.path\n",
    "    blockshift_p1 = False\n",
    "\n",
    "    if args.drtk is not None:\n",
    "        blockshift_p1 = True\n",
    "        DRTK_TXT_FILE = args.drtk\n",
    "        print(\"P1 blockshift set\")\n",
    "\n",
    "        with open(DRTK_TXT_FILE, 'r') as file:\n",
    "            line = file.readline()\n",
    "            split_line = line.split(',')\n",
    "            drtk_field = cartesian_to_geog(float(split_line[0]), float(split_line[1]), float(split_line[2]))\n",
    "            line = file.readline()\n",
    "            split_line = line.split(',')\n",
    "            drtk_auspos = cartesian_to_geog(float(split_line[0]), float(split_line[1]), float(split_line[2]))\n",
    "\n",
    "        diff_lat = round((drtk_auspos.lat_decdeg - drtk_field.lat_decdeg), 6)\n",
    "        diff_lon = round((drtk_auspos.lon_decdeg - drtk_field.lon_decdeg), 6)\n",
    "        diff_elliph = round((drtk_auspos.elliph - drtk_field.elliph), 6)\n",
    "        P1_shift = Metashape.Vector((diff_lon, diff_lat, diff_elliph))\n",
    "\n",
    "        print(\"Shifting P1 cameras by: \" + str(P1_shift))\n",
    "\n",
    "        for camera in chunk.cameras:\n",
    "            if not camera.label == camera.master.label:\n",
    "                continue\n",
    "            if not camera.reference.location:\n",
    "                continue\n",
    "            else:\n",
    "                camera.reference.location = camera.reference.location + P1_shift\n",
    "\n",
    "    target_crs = Metashape.CoordinateSystem(\"EPSG::\" + args.crs)\n",
    "    for camera in chunk.cameras:\n",
    "        if not camera.reference.location:\n",
    "            continue\n",
    "        camera.reference.location = Metashape.CoordinateSystem.transform(camera.reference.location, SOURCE_CRS, target_crs)\n",
    "\n",
    "    chunk.crs = target_crs\n",
    "\n",
    "    global P1_shift_vec\n",
    "    if blockshift_p1:\n",
    "        chunk.exportReference(path=str(P1_CAM_CSV), format=Metashape.ReferenceFormatCSV, columns=\"nxyz\", delimiter=\",\", items=Metashape.ReferenceItemsCameras)\n",
    "        P1_shift_vec = np.array([diff_lat, diff_lon, diff_elliph])\n",
    "    else:\n",
    "        P1_shift_vec = np.array([0.0, 0.0, 0.0])\n",
    "\n",
    "    doc.save()\n",
    "\n",
    "    if METASHAPE_V2_PLUS:\n",
    "        chunk.analyzeImages()\n",
    "    else:\n",
    "        chunk.analyzePhotos()\n",
    "    low_img_qual = [camera for camera in chunk.cameras if (float(camera.meta[\"Image/Quality\"]) < IMG_QUAL_THRESHOLD)]\n",
    "    if low_img_qual:\n",
    "        print(\"Removing cameras with Image Quality < %.1f\" % IMG_QUAL_THRESHOLD)\n",
    "        chunk.remove(low_img_qual)\n",
    "    doc.save()\n",
    "\n",
    "    print(chunk.sensors[0].antenna.location_ref)\n",
    "    print(\"Update GPS/INS offset for P1\")\n",
    "    chunk.sensors[0].antenna.location_ref = Metashape.Vector(P1_GIMBAL1_OFFSET)\n",
    "    print(chunk.sensors[0].antenna.location_ref)\n",
    "\n",
    "    print(\"Aligning Cameras\")\n",
    "    chunk.camera_location_accuracy = Metashape.Vector((0.10, 0.10, 0.10))\n",
    "    chunk.matchPhotos(downscale=quality1, generic_preselection=False, reference_preselection=True, reference_preselection_mode=Metashape.ReferencePreselectionSource)\n",
    "    chunk.alignCameras()\n",
    "    doc.save()\n",
    "\n",
    "    print(\"Gradual selection for reprojection error...\")\n",
    "    f = Metashape.TiePoints.Filter()\n",
    "    threshold = 0.5\n",
    "    f.init(chunk, criterion=Metashape.TiePoints.Filter.ReprojectionError)\n",
    "    f.removePoints(threshold)\n",
    "    doc.save()\n",
    "\n",
    "    print(\"Optimise alignment\")\n",
    "    chunk.optimizeCameras()\n",
    "    doc.save()\n",
    "\n",
    "    print(\"Build dense cloud\")\n",
    "    chunk.buildDepthMaps(downscale=quality2)\n",
    "    doc.save()\n",
    "\n",
    "    if METASHAPE_V2_PLUS:\n",
    "        chunk.buildPointCloud()\n",
    "    else:\n",
    "        chunk.buildDenseCloud()\n",
    "    doc.save()\n",
    "\n",
    "    if use_model:\n",
    "        print(\"Build mesh\")\n",
    "        if METASHAPE_V2_PLUS:\n",
    "            chunk.buildModel(surface_type=Metashape.HeightField, source_data=Metashape.PointCloudData, face_count=Metashape.MediumFaceCount)\n",
    "        else:\n",
    "            chunk.buildModel(surface_type=Metashape.HeightField, source_data=Metashape.DenseCloudData, face_count=Metashape.MediumFaceCount)\n",
    "        doc.save()\n",
    "\n",
    "        chunk.decimateModel(face_count=len(chunk.model.faces) / 2)\n",
    "        smooth_val = DICT_SMOOTH_STRENGTH[args.smooth]\n",
    "        chunk.smoothModel(smooth_val)\n",
    "        model_file = Path(proj_file).parent / (Path(proj_file).stem + \"_rgb_smooth_\" + str(smooth_val) + \".obj\")\n",
    "        chunk.exportModel(path=str(model_file), crs=target_crs, format=Metashape.ModelFormatOBJ)\n",
    "\n",
    "    compression = Metashape.ImageCompression()\n",
    "    compression.tiff_compression = Metashape.ImageCompression.TiffCompressionLZW\n",
    "    compression.tiff_big = True\n",
    "    compression.tiff_tiled = True\n",
    "    compression.tiff_overviews = True\n",
    "\n",
    "    if use_dem:\n",
    "        print(\"Build DEM\")\n",
    "        dem_res_xy = 0.01\n",
    "        if METASHAPE_V2_PLUS:\n",
    "            chunk.buildDem(source_data=Metashape.PointCloudData, resolution=dem_res_xy)\n",
    "        else:\n",
    "            chunk.buildDem(source_data=Metashape.DenseCloudData, resolution=dem_res_xy)\n",
    "        doc.save()\n",
    "\n",
    "        dem_file = Path(proj_file).parent / (Path(proj_file).stem + \"_dem_\" + str(dem_res_xy).split('.')[1] + \".tif\")\n",
    "        chunk.exportRaster(path=dem_file, source_data=Metashape.ElevationData, image_format=Metashape.ImageFormatTIFF, image_compression=compression)\n",
    "\n",
    "    test = args.test\n",
    "\n",
    "    if not test:\n",
    "        print(\"Build orthomosaic\")\n",
    "        chunk.buildOrthomosaic(surface_data=Metashape.DataSource.ModelData, refine_seamlines=True)\n",
    "        doc.save()\n",
    "\n",
    "        if chunk.orthomosaic:\n",
    "            res_xy = 0.01\n",
    "            p1_idx = MRK_PATH.find(\"rgb\")\n",
    "            if p1_idx == -1:\n",
    "                dir_path = Path(proj_file).parent\n",
    "                print(\"Cannot find rgb/ folder. Saving ortho in \" + str(dir_path))\n",
    "            else:\n",
    "                dir_path = Path(MRK_PATH[:p1_idx + len(\"rgb\")]) / \"level1_proc\"\n",
    "                dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            ortho_file = dir_path / (Path(proj_file).stem + \"_rgb_ortho_\" + str(res_xy).split('.')[1] + \".tif\")\n",
    "            chunk.exportRaster(path=str(ortho_file), resolution_x=res_xy, resolution_y=res_xy, image_format=Metashape.ImageFormatTIFF, save_alpha=False, source_data=Metashape.OrthomosaicData, image_compression=compression)\n",
    "            print(\"Exported orthomosaic \" + str(ortho_file))\n",
    "        else:\n",
    "            print(\"Skipping orthomosaic building and exporting due to test mode.\")\n",
    "\n",
    "        report_path = dir_path / (Path(proj_file).stem + \"_rgb_report.pdf\")\n",
    "        print(f\"Exporting processing report to {report_path}...\")\n",
    "        chunk.exportReport(path=str(report_path))\n",
    "        doc.save()\n",
    "\n",
    "        print(\"RGB chunk processing complete!\")\n",
    "\n",
    "def proc_multispec():\n",
    "    \"\"\"\n",
    "    Process multispectral images to create orthomosaic with relative reflectance.\n",
    "    \"\"\"\n",
    "    chunk = doc.findChunk(dict_chunks[CHUNK_MULTISPEC])\n",
    "    target_crs = Metashape.CoordinateSystem(\"EPSG::\" + args.crs)\n",
    "    camera = chunk.cameras[0]\n",
    "    cam_master = camera.master.label.split('_')\n",
    "    img_suffix_master = cam_master[2]\n",
    "\n",
    "    global P1_shift_vec\n",
    "    if args.multionly:\n",
    "        P1_shift_vec = np.array([0.0, 0.0, 0.0])\n",
    "\n",
    "    print(\"Interpolate Micasense position based on P1 with blockshift\" + str(P1_shift_vec))\n",
    "    ret_micasense_pos(MRK_PATH, MICASENSE_PATH, img_suffix_master, args.crs, str(MICASENSE_CAM_CSV), P1_shift_vec)\n",
    "    chunk.importReference(str(MICASENSE_CAM_CSV), format=Metashape.ReferenceFormatCSV, columns=\"nxyz\", delimiter=\",\", crs=target_crs, skip_rows=1, items=Metashape.ReferenceItemsCameras)\n",
    "    doc.save()\n",
    "\n",
    "    del_camera_names = list()\n",
    "    for camera in chunk.cameras:\n",
    "        if not camera.label == camera.master.label:\n",
    "            continue\n",
    "        if not camera.reference.location:\n",
    "            continue\n",
    "        if camera.reference.location.z == 0:\n",
    "            del_camera_names.append(camera.label)\n",
    "\n",
    "    print(\"Deleting MicaSense images that triggered outside P1 capture times\")\n",
    "    for camera in chunk.cameras:\n",
    "        if camera.group is not None:\n",
    "            if camera.group.label == 'Calibration images':\n",
    "                continue\n",
    "        if camera.label in del_camera_names:\n",
    "            chunk.remove(camera)\n",
    "    doc.save()\n",
    "\n",
    "    if cam_model == 'RedEdge-M':\n",
    "        set_primary = \"NIR\"\n",
    "    elif cam_model == 'RedEdge-P':\n",
    "        set_primary = 'Panchro'\n",
    "    for s in chunk.sensors:\n",
    "        if s.label.find(set_primary) != -1:\n",
    "            print(\"Setting primary channel to \" + s.label)\n",
    "            chunk.primary_channel = s.layer_index\n",
    "            break\n",
    "\n",
    "    print(\"Updating Micasense GPS offset\")\n",
    "    chunk.sensors[0].antenna.location_ref = Metashape.Vector(MS_GIMBAL2_OFFSET)\n",
    "\n",
    "    print(\"Updating Raster Transform for relative reflectance\")\n",
    "    raster_transform_formula = []\n",
    "    num_bands = len(chunk.sensors)\n",
    "    if cam_model == 'RedEdge-M':\n",
    "        for band in range(1, num_bands + 1):\n",
    "            raster_transform_formula.append(\"B\" + str(band) + \"/32768\")\n",
    "    elif cam_model == 'RedEdge-P':\n",
    "        if num_bands >= 10:\n",
    "            PANCHRO_BAND = 5\n",
    "        else:\n",
    "            PANCHRO_BAND = 3\n",
    "        for band in range(1, num_bands + 1):\n",
    "            if band != PANCHRO_BAND:\n",
    "                raster_transform_formula.append(\"B\" + str(band) + \"/32768\")\n",
    "\n",
    "    chunk.raster_transform.formula = raster_transform_formula\n",
    "    chunk.raster_transform.calibrateRange()\n",
    "    chunk.raster_transform.enabled = True\n",
    "    doc.save()\n",
    "\n",
    "    if METASHAPE_V2_PLUS:\n",
    "        chunk.analyzeImages()\n",
    "    else:\n",
    "        chunk.analyzePhotos()\n",
    "    low_img_qual = [camera.master for camera in chunk.cameras if (float(camera.meta[\"Image/Quality\"]) < 0.5)]\n",
    "    if low_img_qual:\n",
    "        print(\"Removing cameras with Image Quality < %.1f\" % 0.5)\n",
    "        chunk.remove(list(set(low_img_qual)))\n",
    "    doc.save()\n",
    "\n",
    "    chunk.calibrateReflectance(use_reflectance_panels=True, use_sun_sensor=args.sunsens)\n",
    "\n",
    "    chunk.camera_location_accuracy = Metashape.Vector((0.10, 0.10, 0.10))\n",
    "    chunk.matchPhotos(downscale=quality3, generic_preselection=False, reference_preselection=True, reference_preselection_mode=Metashape.ReferencePreselectionSource)\n",
    "    doc.save()\n",
    "    print(\"Aligning cameras\")\n",
    "    chunk.alignCameras()\n",
    "    doc.save()\n",
    "\n",
    "    print(\"Gradual selection for reprojection error...\")\n",
    "    f = Metashape.TiePoints.Filter()\n",
    "    threshold = 0.5\n",
    "    f.init(chunk, criterion=Metashape.TiePoints.Filter.ReprojectionError)\n",
    "    f.removePoints(threshold)\n",
    "    doc.save()\n",
    "\n",
    "    print(\"Optimise alignment\")\n",
    "    chunk.optimizeCameras()\n",
    "    doc.save()\n",
    "\n",
    "    copyBoundingBox(CHUNK_RGB, CHUNK_MULTISPEC)\n",
    "\n",
    "    if use_model:\n",
    "        smooth_val = DICT_SMOOTH_STRENGTH[args.smooth]\n",
    "        model_file = Path(proj_file).parent / (Path(proj_file).stem + \"_rgb_smooth_\" + str(smooth_val) + \".obj\")\n",
    "        chunk.importModel(path=str(model_file), crs=target_crs, format=Metashape.ModelFormatOBJ)\n",
    "\n",
    "        print(\"Build orthomosaic\")\n",
    "        chunk.buildOrthomosaic(surface_data=Metashape.DataSource.ModelData, refine_seamlines=True)\n",
    "        doc.save()\n",
    "\n",
    "    if use_dem:\n",
    "        dem_res_xy = 0.01\n",
    "        dem_file = Path(proj_file).parent / (Path(proj_file).stem + \"_dem_\" + str(dem_res_xy).split('.')[1] + \".tif\")\n",
    "        chunk.importRaster(path=dem_file, crs=target_crs, format=Metashape.ImageFormatTIFF)\n",
    "\n",
    "        print(\"Build orthomosaic\")\n",
    "        chunk.buildOrthomosaic(surface_data=Metashape.DataSource.ElevationData, refine_seamlines=True)\n",
    "        doc.save()\n",
    "\n",
    "    if chunk.orthomosaic:\n",
    "        res_xy = 0.05\n",
    "        micasense_idx = MICASENSE_PATH.find(\"multispec\")\n",
    "        if micasense_idx == -1:\n",
    "            dir_path = Path(proj_file).parent\n",
    "            print(\"Cannot find \" + \"multispec/ folder. Saving ortho in \" + str(dir_path))\n",
    "        else:\n",
    "            dir_path = Path(MICASENSE_PATH[:micasense_idx + len(\"multispec\")]) / \"level1_proc\"\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        ortho_file = dir_path / (Path(proj_file).stem + \"_\" + \"multispec_ortho_\" + str(res_xy).split('.')[1] + \".tif\")\n",
    "        compression = Metashape.ImageCompression()\n",
    "        compression.tiff_compression = Metashape.ImageCompression.TiffCompressionLZW\n",
    "        compression.tiff_big = True\n",
    "        compression.tiff_tiled = True\n",
    "        compression.tiff_overviews = True\n",
    "\n",
    "        chunk.exportRaster(path=str(ortho_file), resolution_x=res_xy, resolution_y=res_xy, image_format=Metashape.ImageFormatTIFF, raster_transform=Metashape.RasterTransformValue, save_alpha=False, source_data=Metashape.OrthomosaicData, image_compression=compression)\n",
    "        print(\"Exported orthomosaic: \" + str(ortho_file))\n",
    "\n",
    "    report_path = dir_path / (Path(proj_file).stem + \"_multispec_report.pdf\")\n",
    "    print(f\"Exporting processing report to {report_path}...\")\n",
    "    chunk.exportReport(path=str(report_path))\n",
    "    doc.save()\n",
    "\n",
    "    print(\"Multispec chunk processing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Argument Parsing and Initialization\n",
    "Set up argument parsing using argparse and initialize variables such as MRK_PATH, MICASENSE_PATH, and doc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(proj_path=None, date='20240723', site='Site_test5', crs='2056', multispec='M:\\\\working_package_2\\\\2024_dronecampaign\\\\01_data\\\\dronetest\\\\MicasenseData\\\\fullset', rgb='M:\\\\working_package_2\\\\2024_dronecampaign\\\\01_data\\\\dronetest\\\\P1Data\\\\DJI_202408080937_002_p1micasense60mtest', smooth='low', drtk=None, sunsens=False, test=False, multionly=False)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "# Simulate command-line arguments\n",
    "args_list = [\n",
    "    '-date', '20240723',\n",
    "    '-site', 'Site_test5',\n",
    "    '-crs', '2056',\n",
    "    '-multispec', 'M:\\\\working_package_2\\\\2024_dronecampaign\\\\01_data\\\\dronetest\\\\MicasenseData\\\\fullset',\n",
    "    '-rgb', 'M:\\\\working_package_2\\\\2024_dronecampaign\\\\01_data\\\\dronetest\\\\P1Data\\\\DJI_202408080937_002_p1micasense60mtest',\n",
    "    '-smooth', 'low',\n",
    "    '-test', 'True'\n",
    "]\n",
    "\n",
    "# Parse arguments\n",
    "parser = argparse.ArgumentParser(description='Update camera positions in P1 and/or MicaSense chunks in Metashape project')\n",
    "parser.add_argument('-proj_path', help='path to Metashape project file')\n",
    "parser.add_argument('-date', help='Date of flight in YYYYMMDD format', required=True)\n",
    "parser.add_argument('-site', help='Site name', required=True)\n",
    "parser.add_argument('-crs', help='EPSG code for target projected CRS for micasense cameras. E.g: 7855 for GDA2020/MGA zone 55', required=True)\n",
    "parser.add_argument('-multispec', help='path to multispectral level0_raw folder with raw images')\n",
    "parser.add_argument('-rgb', help='path to RGB level0_raw folder that also has the MRK files')\n",
    "parser.add_argument('-smooth', help='Smoothing strength used to smooth RGB mesh low/med/high', default=\"low\")\n",
    "parser.add_argument('-drtk', help='If RGB coordinates to be blockshifted, file containing DRTK base station coordinates from field and AUSPOS', default=None)\n",
    "parser.add_argument('-sunsens', help='boolean to use sun sensor data for reflectance calibration', default=False)\n",
    "parser.add_argument('-test', help='boolean to make processing faster for debugging', default=False)\n",
    "parser.add_argument('-multionly', help='boolean to process multispec chunk only', default=False)\n",
    "\n",
    "args = parser.parse_args(args_list)\n",
    "\n",
    "# Print parsed arguments to verify\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Argument Parsing and Initialization\n",
    "\n",
    "# Parse arguments and initialize variables\n",
    "parser = argparse.ArgumentParser(description='Update camera positions in P1 and/or MicaSense chunks in Metashape project')\n",
    "parser.add_argument('-proj_path', help='path to Metashape project file')\n",
    "parser.add_argument('-date', help='Date of flight in YYYYMMDD format', required=True)\n",
    "parser.add_argument('-site', help='Site name', required=True)\n",
    "parser.add_argument('-crs', help='EPSG code for target projected CRS for micasense cameras. E.g: 7855 for GDA2020/MGA zone 55', required=True)\n",
    "parser.add_argument('-multispec', help='path to multispectral level0_raw folder with raw images')\n",
    "parser.add_argument('-rgb', help='path to RGB level0_raw folder that also has the MRK files')\n",
    "parser.add_argument('-smooth', help='Smoothing strength used to smooth RGB mesh low/med/high', default=\"low\")\n",
    "parser.add_argument('-drtk', help='If RGB coordinates to be blockshifted, file containing DRTK base station coordinates from field and AUSPOS', default=None)\n",
    "parser.add_argument('-sunsens', help='boolean to use sun sensor data for reflectance calibration', default=False)\n",
    "parser.add_argument('-test', help='boolean to make processing faster for debugging', default=False)\n",
    "parser.add_argument('-multionly', help='boolean to process multispec chunk only', default=False)\n",
    "\n",
    "args = parser.parse_args(args_list)\n",
    "\n",
    "# Initialize global variables\n",
    "MRK_PATH = args.rgb if args.rgb else None\n",
    "MICASENSE_PATH = args.multispec if args.multispec else None\n",
    "\n",
    "# Initialize Metashape document\n",
    "doc = Metashape.Document()\n",
    "if args.proj_path:\n",
    "    proj_file = args.proj_path\n",
    "    doc.open(proj_file, read_only=False)  # Open the document in editable mode\n",
    "else:\n",
    "    proj_file = doc.path\n",
    "\n",
    "if not proj_file:\n",
    "    site = args.site\n",
    "    date = args.date\n",
    "    proj_file = os.path.join(BASE_DIR, site, date, f\"{site}_{date}_metashape.psx\")\n",
    "    if not os.path.exists(proj_file):\n",
    "        doc.save(proj_file)\n",
    "    doc.open(proj_file, read_only=False)  # Open the document in editable mode\n",
    "    doc.save(proj_file)\n",
    "\n",
    "# Validate paths\n",
    "if not MRK_PATH:\n",
    "    MRK_PATH = Path(proj_file).parents[1] / \"rgb/level0_raw\"\n",
    "    if not MRK_PATH.is_dir():\n",
    "        sys.exit(f\"{MRK_PATH} directory does not exist. Check and input paths using -rgb\")\n",
    "    MRK_PATH = str(MRK_PATH)\n",
    "\n",
    "if not MICASENSE_PATH:\n",
    "    MICASENSE_PATH = Path(proj_file).parents[1] / \"multispec/level0_raw\"\n",
    "    if not MICASENSE_PATH.is_dir():\n",
    "        sys.exit(f\"{MICASENSE_PATH} directory does not exist. Check and input paths using -multispec\")\n",
    "    MICASENSE_PATH = str(MICASENSE_PATH)\n",
    "\n",
    "if args.drtk and not Path(args.drtk).is_file():\n",
    "    sys.exit(f\"{args.drtk} file does not exist. Check and input correct path using -drtk option\")\n",
    "\n",
    "if args.smooth not in DICT_SMOOTH_STRENGTH:\n",
    "    sys.exit(\"Value for -smooth must be one of low, medium or high.\")\n",
    "\n",
    "# Set quality values for the downscale value in RGB and Multispec for testing\n",
    "quality1 = 4 if args.test else 1\n",
    "quality2 = 8 if args.test else 4\n",
    "quality3 = 4 if args.test else 1\n",
    "\n",
    "# Export blockshifted P1 positions. Not used in script. Useful for debug or to restart parts of script following any issues.\n",
    "P1_CAM_CSV = Path(proj_file).parent / \"dbg_shifted_p1_pos.csv\"\n",
    "# By default save the CSV with updated MicaSense positions in the MicaSense folder. CSV used within script.\n",
    "MICASENSE_CAM_CSV = Path(proj_file).parent / \"interpolated_micasense_pos.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Images to Project\n",
    "Add RGB and multispectral images to the Metashape project, create chunks, and set up the project structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Document.save(): editing is disabled in read-only mode",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m     doc\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Execute the function to add images to the project\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[43madd_images_to_project\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36madd_images_to_project\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m chunk_multispec\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m=\u001b[39m CHUNK_MULTISPEC\n\u001b[0;32m     23\u001b[0m chunk_multispec\u001b[38;5;241m.\u001b[39maddPhotos(micasense_images)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: Document.save(): editing is disabled in read-only mode"
     ]
    }
   ],
   "source": [
    "# Add RGB and multispectral images to the Metashape project, create chunks, and set up the project structure.\n",
    "\n",
    "# Function to add images to the project\n",
    "def add_images_to_project():\n",
    "    global doc, MRK_PATH, MICASENSE_PATH\n",
    "\n",
    "    # Add RGB images\n",
    "    p1_images = find_files(MRK_PATH, (\".jpg\", \".jpeg\", \".tif\", \".tiff\"))\n",
    "    chunk_rgb = doc.addChunk()\n",
    "    chunk_rgb.label = CHUNK_RGB\n",
    "    chunk_rgb.addPhotos(p1_images)\n",
    "\n",
    "    # Check that chunk is not empty and images are in default WGS84 CRS\n",
    "    if len(chunk_rgb.cameras) == 0:\n",
    "        sys.exit(\"Chunk rgb empty\")\n",
    "    if \"EPSG::4326\" not in str(chunk_rgb.crs):\n",
    "        sys.exit(\"Chunk rgb: script expects images loaded to be in CRS WGS84 EPSG::4326\")\n",
    "\n",
    "    # Add multispectral images\n",
    "    micasense_images = find_files(MICASENSE_PATH, (\".jpg\", \".jpeg\", \".tif\", \".tiff\"))\n",
    "    chunk_multispec = doc.addChunk()\n",
    "    chunk_multispec.label = CHUNK_MULTISPEC\n",
    "    chunk_multispec.addPhotos(micasense_images)\n",
    "    doc.save()\n",
    "\n",
    "# Execute the function to add images to the project\n",
    "add_images_to_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if required chunks are present in the project\n",
    "check_chunk_list = [CHUNK_RGB, CHUNK_MULTISPEC]\n",
    "dict_chunks = {}\n",
    "for get_chunk in doc.chunks:\n",
    "    dict_chunks.update({get_chunk.label: get_chunk.key})\n",
    "\n",
    "chunk = doc.findChunk(dict_chunks[CHUNK_RGB])\n",
    "if not chunk:\n",
    "    sys.exit(\"Chunk rgb not found in the project\")\n",
    "\n",
    "chunk = doc.findChunk(dict_chunks[CHUNK_MULTISPEC])\n",
    "if not chunk:\n",
    "    sys.exit(\"Chunk multispec not found in the project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Processing\n",
    "Define the `resume_proc` function to resume processing after user input on calibration images and call the main processing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_proc():\n",
    "    \"\"\"\n",
    "    Resume processing after user input on calibration images.\n",
    "    \"\"\"\n",
    "    # Process RGB chunk if multionly is not set\n",
    "    if not args.multionly:\n",
    "        proc_rgb()\n",
    "    # Process multispec chunk\n",
    "    proc_multispec()\n",
    "    print(\"End of script\")\n",
    "\n",
    "# Execute the resume_proc function to start processing\n",
    "resume_proc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
