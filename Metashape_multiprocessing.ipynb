{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script start\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-proj_path PROJ_PATH] -date DATE -site SITE\n",
      "                             -crs CRS [-multispec MULTISPEC] [-rgb RGB]\n",
      "                             [-smooth SMOOTH] [-drtk DRTK] [-sunsens SUNSENS]\n",
      "                             [-test TEST] [-multionly MULTIONLY]\n",
      "ipykernel_launcher.py: error: the following arguments are required: -date, -site, -crs\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Agisoft\\Metashape Pro\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\"\"\n",
    "This script processes images captured by DJI Zenmuse P1 (gimbal 1) and MicaSense RedEdge-MX/Dual (gimbal 2) sensors \n",
    "using the Matrice 300 RTK drone system. It assumes a specific folder structure as per TERN protocols and provides \n",
    "options to override raw data paths.\n",
    "The script performs the following tasks:\n",
    "1. Adds RGB and multispectral images to the Metashape project.\n",
    "2. Stops for user input on calibration images.\n",
    "3. Resumes processing to complete the workflow, including:\n",
    "    - Blockshifting P1 (RGB camera) coordinates if required.\n",
    "    - Converting coordinates to the target CRS.\n",
    "    - Checking image quality and removing low-quality images.\n",
    "    - Applying GPS/INS offsets.\n",
    "    - Aligning images.\n",
    "    - Building dense clouds and models.\n",
    "    - Smoothing and exporting models.\n",
    "    - Building and exporting orthomosaics.\n",
    "    - Calibrating reflectance for multispectral images.\n",
    "Functions:\n",
    "    - cartesian_to_geog(X, Y, Z): Converts Cartesian coordinates to geographic coordinates using WGS84 ellipsoid.\n",
    "    - find_files(folder, types): Finds files of specified types in a folder.\n",
    "    - copyBoundingBox(from_chunk_label, to_chunk_labels): Copies bounding box from one chunk to others.\n",
    "    - proc_rgb(): Processes RGB images to create orthomosaic and 3D model.\n",
    "    - proc_multispec(): Processes multispectral images to create orthomosaic with relative reflectance.\n",
    "    - resume_proc(): Resumes processing after user input on calibration images.\n",
    "Usage:\n",
    "    Run the script with the required and optional inputs as arguments. Follow the instructions in the console to \n",
    "    complete the calibration steps and resume processing.\n",
    "\"\"\"\"\"\n",
    "\"\"\"\n",
    "Created August 2021\n",
    "\n",
    "@author: Poornima Sivanandam\n",
    "\n",
    "Script to process DJI Zenmuse P1 (gimbal 1) and MicaSense RedEdge-MX/Dual (gimbal 2) images captured simultaneously\n",
    "using the Matrice 300 RTK drone system.\n",
    "\n",
    "Assumption that folder structure is as per the TERN protocols:\n",
    "Data |\tPath | Example\n",
    "Raw data |\t<plot>/YYYYMMDD/imagery/<sensor>/level0_raw/ |\tSASMDD0001/20220519/imagery/rgb/level0_raw\n",
    "Data products |\t<plot>/YYYYMMDD/imagery/<sensor>/level1_proc/\t| SASMDD0001/20220519/imagery/multispec/level1_proc\n",
    "Metashape project |\tplot/YYYYMMDD/imagery/metashape| SASRIV0001/20220516/imagery/metashape/\n",
    "DRTK logs | plot/YYYYMMDD/drtk/\n",
    "\n",
    "Raw data paths can be overriden using 'Optional Inputs'.\n",
    "\n",
    "Required Input:\n",
    "    -crs \"<EPSG code for target projected coordinate reference system. Also used in MicaSense position interpolation>\"\n",
    "    Example: -crs \"7855\"\n",
    "    See https://epsg.org/home.html\n",
    "\n",
    "Optional Inputs:\n",
    "    1. -multispec \"path to multispectral level0_raw folder containing raw data\"\n",
    "        Default is relative to project location: ../multispec/level0_raw/\n",
    "    2. -rgb \"path to RGB level0_raw folder which also has the MRK file(s)\"\n",
    "        Default is relative to project location: ../rgb/level0_raw/\n",
    "    3. -smooth \"<low/medium/high>\"\n",
    "        Strength value to smooth RGB model. Default is low.\n",
    "        Low: for low-lying vegetation (grasslands, shrublands), Medium and high: as appropriate for forested sites.\n",
    "    4. When P1 (RGB camera) coordinates have to be blockshifted:\n",
    "        - Path to file containing DRTK init and AUSPOS cartesian coords passed using \"-drtk <path to file>\".\n",
    "\n",
    "Summary:\n",
    "    * Add RGB and multispectral images.\n",
    "    * Stop script for user input on calibration images.\n",
    "    * When 'Resume Processing' is clicked complete the processing workflow.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import math\n",
    "import collections\n",
    "import numpy as np\n",
    "import Metashape\n",
    "import os\n",
    "import sys\n",
    "import exifread\n",
    "from collections import defaultdict\n",
    "from upd_micasense_pos import ret_micasense_pos\n",
    "import importlib\n",
    "import upd_micasense_pos\n",
    "import csv\n",
    "\n",
    "\n",
    "importlib.reload(upd_micasense_pos)\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Note: External modules imported were installed through:\n",
    "# \"C:\\Program Files\\Agisoft\\Metashape Pro\\python\\python.exe\" -m pip install <modulename>\n",
    "# See M300 data processing protocol for more information.\n",
    "\n",
    "# Metashape Python API updates in v2.0\n",
    "METASHAPE_V2_PLUS = False\n",
    "found_version = Metashape.app.version.split('.')  # e.g. 2.0.1\n",
    "if int(found_version[0]) >= 2:\n",
    "    METASHAPE_V2_PLUS = True\n",
    "\n",
    "###############################################################################\n",
    "# BASE DIRECTORY If you run multiple projects, update this path\n",
    "# Decoide if you want to use model or DEM or for Orthomoasaic\n",
    "###############################################################################\n",
    "\n",
    "BASE_DIR = \"M:/working_package_2/2024_dronecampaign/01_data/dronetest/processing_test\"\n",
    "\n",
    "use_model = False\n",
    "use_dem = True\n",
    "\n",
    "###############################################################################\n",
    "# Constants\n",
    "###############################################################################\n",
    "GEOG_COORD = collections.namedtuple('Geog_CS', ['lat_decdeg', 'lon_decdeg', 'elliph'])\n",
    "\n",
    "SOURCE_CRS = Metashape.CoordinateSystem(\"EPSG::4326\")  # WGS84\n",
    "\n",
    "CONST_a = 6378137  # Semi major axis\n",
    "CONST_inv_f = 298.257223563  # Inverse flattening 1/f WGS84 ellipsoid\n",
    "# Chunks in Metashape\n",
    "CHUNK_RGB = \"rgb\"\n",
    "CHUNK_MULTISPEC = \"multispec\"\n",
    "\n",
    "IMG_QUAL_THRESHOLD = 0.7\n",
    "\n",
    "DICT_SMOOTH_STRENGTH = {'low': 50, 'medium': 100, 'high': 200}\n",
    "\n",
    "# Lever-arm offsets for different sensors on *Matrice 300*\n",
    "# TODO: update this for other sensors and drone platforms\n",
    "P1_GIMBAL1_OFFSET = (0.087, 0.0, 0.0)\n",
    "\n",
    "# Measure lever-arm offsets (X, Y, Z) from the single gimbal position to the ‘master’ camera (by default, the lowest wavelength)\n",
    "# In Metashape, the offsets are positive with respect to the actual camera positions. \n",
    "# See Metashape manual or TERN RGB Multispectral processing protocol for details.\n",
    "offset_dict = defaultdict(dict)\n",
    "offset_dict['RedEdge-M']['Red'] = (-0.097, -0.03, -0.06)\n",
    "offset_dict['RedEdge-M']['Dual'] = (-0.097, 0.02, -0.08)\n",
    "offset_dict['RedEdge-P']['Red'] = (0,0,0)\n",
    "offset_dict['RedEdge-P']['Dual'] = (0,0,0)\n",
    "\n",
    "###############################################################################\n",
    "# Function definitions\n",
    "###############################################################################\n",
    "def cartesian_to_geog(X, Y, Z):\n",
    "    \"\"\"\n",
    "    Author: Poornima Sivanandam\n",
    "    Convert Cartesian coordinates to geographic coordinates using WGS84 ellipsoid.\n",
    "    Return Lat, Lon, ellipsoidal height as a named tuple.\n",
    "    Calculations from Transformation_Conversion.xlsx at https://github.com/icsm-au/DatumSpreadsheets\n",
    "    \"\"\"\n",
    "    f = 1 / CONST_inv_f\n",
    "    e_sq = 2 * f - f ** 2\n",
    "    p = math.sqrt(X ** 2 + Y ** 2)\n",
    "    r = math.sqrt(p ** 2 + Z ** 2)\n",
    "    mu = math.atan((Z / p) * (1 - f) + (e_sq * CONST_a) / r)\n",
    "\n",
    "    lat_top_line = Z * (1 - f) + e_sq * CONST_a * math.sin(mu) ** 3\n",
    "    lat_bottom_line = (1 - f) * (p - e_sq * CONST_a * math.cos(mu) ** 3)\n",
    "\n",
    "    lon = math.atan(Y / X)\n",
    "    lat = math.atan(lat_top_line / lat_bottom_line)\n",
    "\n",
    "    if (lon < 0):\n",
    "        tmp_lon = lon + math.pi\n",
    "    else:\n",
    "        tmp_lon = lon\n",
    "\n",
    "    lon_dec_deg = (tmp_lon / math.pi) * 180\n",
    "    lat_dec_deg = (lat / math.pi) * 180\n",
    "\n",
    "    ellip_h = p * math.cos(lat) + Z * math.sin(lat) - CONST_a * math.sqrt(1 - e_sq * math.sin(lat) ** 2)\n",
    "\n",
    "    conv_coord = GEOG_COORD(lat_dec_deg, lon_dec_deg, ellip_h)\n",
    "\n",
    "    return conv_coord\n",
    "\n",
    "\n",
    "def find_files(folder, types):\n",
    "    photo_list = list()\n",
    "    for dir, subdir, file in os.walk(folder):\n",
    "        for filename in file:\n",
    "            if (filename.lower().endswith(types)):\n",
    "                photo_list.append(os.path.join(dir, filename))\n",
    "    return (photo_list)\n",
    "\n",
    "def copyBoundingBox(from_chunk_label, to_chunk_labels):\n",
    "    print(\"Script started...\")\n",
    "\n",
    "    doc = Metashape.app.document\n",
    "\n",
    "    from_chunk = None\n",
    "    for chunk in doc.chunks:\n",
    "        if chunk.label == from_chunk_label:\n",
    "            from_chunk = chunk\n",
    "            break\n",
    "\n",
    "    if not from_chunk:\n",
    "        print(f\"Chunk with label '{from_chunk_label}' not found.\")\n",
    "        return\n",
    "\n",
    "    to_chunks = []\n",
    "    for chunk in doc.chunks:\n",
    "        if chunk.label in to_chunk_labels:\n",
    "            to_chunks.append(chunk)\n",
    "\n",
    "    if not to_chunks:\n",
    "        print(\"No valid target chunks found.\")\n",
    "        return\n",
    "\n",
    "    print(\"Copying bounding box from chunk '\" + from_chunk.label + \"' to \" + str(len(to_chunks)) + \" chunks...\")\n",
    "\n",
    "    T0 = from_chunk.transform.matrix\n",
    "\n",
    "    region = from_chunk.region\n",
    "    R0 = region.rot\n",
    "    C0 = region.center\n",
    "    s0 = region.size\n",
    "\n",
    "    for chunk in to_chunks:\n",
    "        if chunk == from_chunk:\n",
    "            continue\n",
    "\n",
    "        T = chunk.transform.matrix.inv() * T0\n",
    "\n",
    "        R = Metashape.Matrix([[T[0, 0], T[0, 1], T[0, 2]],\n",
    "                              [T[1, 0], T[1, 1], T[1, 2]],\n",
    "                              [T[2, 0], T[2, 1], T[2, 2]]])\n",
    "\n",
    "        scale = R.row(0).norm()\n",
    "        R = R * (1 / scale)\n",
    "\n",
    "        new_region = Metashape.Region()\n",
    "        new_region.rot = R * R0\n",
    "        c = T.mulp(C0)\n",
    "        new_region.center = c\n",
    "        new_region.size = s0 * scale / 1.\n",
    "\n",
    "        chunk.region = new_region\n",
    "\n",
    "def proc_rgb():\n",
    "    \"\"\"\n",
    "    Author: Poornima Sivanandam\n",
    "    Arguments: None\n",
    "    Return: None\n",
    "    Create: RGB orthomosaic in rgb/level1_proc or in Metashape project folder\n",
    "        smoothed 3D model file in Metashape project folder\n",
    "    Summary:\n",
    "        * blockshift (optional through args)\n",
    "        * convert to target CRS\n",
    "        * Image Quality check\n",
    "        * Apply GPS/INS offset for gimbal 1\n",
    "        * Update Camera Accuracy settings for M300 RTK GNSS accuracy\n",
    "        * Align images\n",
    "        * Build dense cloud\n",
    "        * Build model, decimate and smooth (use args)\n",
    "        * Export model (for multispec chunk)\n",
    "        * Build and export orthomosaic\n",
    "    \"\"\"\n",
    "    # If P1 positions are to be blockshifted, do the following:\n",
    "    # - Read the .txt file and convert Cartesian coordinates to WGS84 Lat/Lon\n",
    "    # - Calculate the difference and apply the shift directly to the cameras (Lon/Lat/Ellipsoidal height) in 'rgb' chunk\n",
    "    # Convert coordinate system for Lat/Lon to target projected coordinate system\n",
    "\n",
    "    chunk = doc.findChunk(dict_chunks[CHUNK_RGB])\n",
    "    proj_file = doc.path\n",
    "    blockshift_p1 = False\n",
    "\n",
    "    if args.drtk is not None:\n",
    "        blockshift_p1 = True\n",
    "        DRTK_TXT_FILE = args.drtk\n",
    "        print(\"P1 blockshift set\")\n",
    "\n",
    "        # read from txt/csv cartesian for RTK initial (line 1) and AUSPOS coords (line 2)\n",
    "        with open(DRTK_TXT_FILE, 'r') as file:\n",
    "            line = file.readline()\n",
    "            split_line = line.split(',')\n",
    "            drtk_field = cartesian_to_geog(float(split_line[0]), float(split_line[1]), float(split_line[2]))\n",
    "            line = file.readline()\n",
    "            split_line = line.split(',')\n",
    "            drtk_auspos = cartesian_to_geog(float(split_line[0]), float(split_line[1]), float(split_line[2]))\n",
    "\n",
    "        # calc difference\n",
    "        diff_lat = round((drtk_auspos.lat_decdeg - drtk_field.lat_decdeg), 6)\n",
    "        diff_lon = round((drtk_auspos.lon_decdeg - drtk_field.lon_decdeg), 6)\n",
    "        diff_elliph = round((drtk_auspos.elliph - drtk_field.elliph), 6)\n",
    "        P1_shift = Metashape.Vector((diff_lon, diff_lat, diff_elliph))\n",
    "\n",
    "        print(\"Shifting P1 cameras by: \" + str(P1_shift))\n",
    "\n",
    "        # shift coordinates in the chunk\n",
    "        for camera in chunk.cameras:\n",
    "            if not camera.label == camera.master.label:\n",
    "                continue\n",
    "            if not camera.reference.location:\n",
    "                continue\n",
    "            else:\n",
    "                camera.reference.location = camera.reference.location + P1_shift\n",
    "\n",
    "    # Convert to projected coordinate system\n",
    "    target_crs = Metashape.CoordinateSystem(\"EPSG::\" + args.crs)\n",
    "    for camera in chunk.cameras:\n",
    "        if not camera.reference.location:\n",
    "            continue\n",
    "        camera.reference.location = Metashape.CoordinateSystem.transform(camera.reference.location, SOURCE_CRS,\n",
    "                                                                         target_crs)\n",
    "\n",
    "    chunk.crs = target_crs\n",
    "\n",
    "    global P1_shift_vec\n",
    "    if blockshift_p1:\n",
    "        # Export updated positions as csv for debug purposes. Not used in script.\n",
    "        chunk.exportReference(path=str(P1_CAM_CSV), format=Metashape.ReferenceFormatCSV, columns=\"nxyz\",\n",
    "                              delimiter=\",\", items=Metashape.ReferenceItemsCameras)\n",
    "\n",
    "        # If P1  blockshifted, pass vector for x, y, z shift of micasense image position\n",
    "        P1_shift_vec = np.array([diff_lat, diff_lon, diff_elliph])\n",
    "    else:\n",
    "        P1_shift_vec = np.array([0.0, 0.0, 0.0])\n",
    "\n",
    "    doc.save()\n",
    "\n",
    "    #\n",
    "    # Estimate image quality and remove cameras with quality < threshold\n",
    "    #\n",
    "    if METASHAPE_V2_PLUS:\n",
    "        chunk.analyzeImages()\n",
    "    else:\n",
    "        chunk.analyzePhotos()\n",
    "    low_img_qual = []\n",
    "    low_img_qual = [camera for camera in chunk.cameras if (float(camera.meta[\"Image/Quality\"]) < IMG_QUAL_THRESHOLD)]\n",
    "    if low_img_qual:\n",
    "        print(\"Removing cameras with Image Quality < %.1f\" % IMG_QUAL_THRESHOLD)\n",
    "        chunk.remove(low_img_qual)\n",
    "    doc.save()\n",
    "\n",
    "    #\n",
    "    # GPS/INS offset\n",
    "    #\n",
    "    print(chunk.sensors[0].antenna.location_ref)\n",
    "    print(\"Update GPS/INS offset for P1\")\n",
    "    chunk.sensors[0].antenna.location_ref = Metashape.Vector(P1_GIMBAL1_OFFSET)\n",
    "    print(chunk.sensors[0].antenna.location_ref)\n",
    "\n",
    "    #\n",
    "    # Align Photos\n",
    "    #\n",
    "    print(\"Aligning Cameras\")\n",
    "    # change camera position accuracy to 0.1 m\n",
    "    chunk.camera_location_accuracy = Metashape.Vector((0.10, 0.10, 0.10))\n",
    "\n",
    "    # Downscale values per https://www.agisoft.com/forum/index.php?topic=11697.0\n",
    "    # Downscale: highest, high, medium, low, lowest: 0, 1, 2, 4, 8\n",
    "    # Quality:  High, Reference Preselection: Source\n",
    "    chunk.matchPhotos(downscale= quality1, generic_preselection=False, reference_preselection=True,\n",
    "                      reference_preselection_mode=Metashape.ReferencePreselectionSource)\n",
    "    chunk.alignCameras()\n",
    "    doc.save()\n",
    "\n",
    "    # Gradual selection based on reprojection error\n",
    "    print(\"Gradual selection for reprojection error...\")\n",
    "    f = Metashape.TiePoints.Filter()\n",
    "    threshold = 0.5\n",
    "    f.init(chunk, criterion=Metashape.TiePoints.Filter.ReprojectionError)\n",
    "    f.removePoints(threshold)\n",
    "    doc.save()\n",
    "    #\n",
    "    # Optimise Cameras\n",
    "    #\n",
    "    print(\"Optimise alignment\")\n",
    "    chunk.optimizeCameras()\n",
    "    doc.save()\n",
    "\n",
    "    #\n",
    "    # Build Dense Cloud\n",
    "    #\n",
    "    # check if exists and reuse depthmap? # reuse_depth=True below\n",
    "    # downscale: ultra, high, medium, low, lowest: 1, 2, 4, 8, 16\n",
    "    print(\"Build dense cloud\")\n",
    "    # Medium quality. And default: mild filtering.\n",
    "    chunk.buildDepthMaps(downscale= quality2)\n",
    "    doc.save()\n",
    "\n",
    "    if METASHAPE_V2_PLUS:\n",
    "        chunk.buildPointCloud()\n",
    "    else:\n",
    "        chunk.buildDenseCloud()\n",
    "    doc.save()\n",
    "\n",
    "    #\n",
    "    # Build Mesh\n",
    "    #\n",
    "    if use_model:\n",
    "\n",
    "        print(\"Build mesh\")\n",
    "        if METASHAPE_V2_PLUS:\n",
    "            chunk.buildModel(surface_type=Metashape.HeightField, source_data=Metashape.PointCloudData,\n",
    "                         face_count=Metashape.MediumFaceCount)\n",
    "        else:\n",
    "            chunk.buildModel(surface_type=Metashape.HeightField, source_data=Metashape.DenseCloudData,\n",
    "                         face_count=Metashape.MediumFaceCount)\n",
    "        doc.save()\n",
    "\n",
    "\n",
    "\n",
    "        # Decimate and smooth mesh to use as orthorectification surface\n",
    "        # Halve face count?\n",
    "        chunk.decimateModel(face_count=len(chunk.model.faces) / 2)\n",
    "        # Smooth model\n",
    "        smooth_val = DICT_SMOOTH_STRENGTH[args.smooth]\n",
    "        chunk.smoothModel(smooth_val)\n",
    "        # Export model for use in micasense chunk\n",
    "        model_file = Path(proj_file).parent / (Path(proj_file).stem + \"_rgb_smooth_\" + str(smooth_val) + \".obj\")\n",
    "        chunk.exportModel(path=str(model_file), crs=target_crs, format=Metashape.ModelFormatOBJ)\n",
    "\n",
    "    #\n",
    "    # Build DEM\n",
    "    #\n",
    "    compression = Metashape.ImageCompression()\n",
    "    compression.tiff_compression = Metashape.ImageCompression.TiffCompressionLZW  # default on Metashape\n",
    "    compression.tiff_big = True\n",
    "    compression.tiff_tiled = True\n",
    "    compression.tiff_overviews = True\n",
    "    \n",
    "    if use_dem:\n",
    "        print(\"Build DEM\")\n",
    "    \n",
    "        # set resolution to 1 cm\n",
    "        dem_res_xy = 0.01\n",
    "\n",
    "        if METASHAPE_V2_PLUS:\n",
    "            chunk.buildDem(source_data=Metashape.PointCloudData,resolution = dem_res_xy )\n",
    "        else:\n",
    "            chunk.buildDem(source_data=Metashape.DenseCloudData,resolution = dem_res_xy )\n",
    "        doc.save()\n",
    "\n",
    "        dem_file = Path(proj_file).parent / (Path(proj_file).stem + \"_dem_\" + str(dem_res_xy).split('.')[1] + \".tif\")    \n",
    "        chunk.exportRaster(path=dem_file, source_data=Metashape.ElevationData, image_format=Metashape.ImageFormatTIFF, image_compression=compression)#include test variable for debugging:\n",
    "\n",
    "    test = args.test #default is False \n",
    "\n",
    "    if not test:\n",
    "        #\n",
    "        # Build and export orthomosaic\n",
    "        #\n",
    "        print(\"Build orthomosaic\")\n",
    "        chunk.buildOrthomosaic(surface_data=Metashape.DataSource.ModelData, refine_seamlines=True)\n",
    "        doc.save()\n",
    "\n",
    "        if chunk.orthomosaic:\n",
    "            # set resolution to 1 cm\n",
    "            res_xy = 0.01\n",
    "\n",
    "            # if rgb/ folder does not exist in MRK_PATH save orthomosaic in the project directory\n",
    "            # else save ortho in rgb/level1_proc/\n",
    "            p1_idx = MRK_PATH.find(\"rgb\")\n",
    "            if p1_idx == -1:\n",
    "                dir_path = Path(proj_file).parent\n",
    "                print(\"Cannot find rgb/ folder. Saving ortho in \" + str(dir_path))\n",
    "            else:\n",
    "                # create p1/level1_proc folder if it does not exist\n",
    "                dir_path = Path(MRK_PATH[:p1_idx + len(\"rgb\")]) / \"level1_proc\"\n",
    "                dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # file naming format: <projname>_rgb_ortho_<res_in_m>.tif\n",
    "            ortho_file = dir_path / (\n",
    "                    Path(proj_file).stem + \"_rgb_ortho_\" + str(res_xy).split('.')[1] + \".tif\")\n",
    "\n",
    "\n",
    "            chunk.exportRaster(path=str(ortho_file), resolution_x=res_xy, resolution_y=res_xy,\n",
    "                               image_format=Metashape.ImageFormatTIFF,\n",
    "                               save_alpha=False, source_data=Metashape.OrthomosaicData, image_compression=compression)\n",
    "            print(\"Exported orthomosaic \" + str(ortho_file))\n",
    "        else:\n",
    "            print(\"Skipping orthomosaic building and exporting due to test mode.\")\n",
    "\n",
    "        # Export the processing report\n",
    "        report_path = dir_path / (\n",
    "                    Path(proj_file).stem + \"_rgb_report.pdf\")\n",
    "        print(f\"Exporting processing report to {report_path}...\")\n",
    "        chunk.exportReport(path = str(report_path))\n",
    "        doc.save()\n",
    "\n",
    "        print(\"RGB chunk processing complete!\")\n",
    "   \n",
    "\n",
    "\n",
    "def proc_multispec():\n",
    "    \"\"\"\n",
    "    Author: Poornima Sivanandam\n",
    "    Arguments: None\n",
    "    Return: None\n",
    "    Create: Multispec orthomosaic in multispec/level1_proc or in Metashape project folder\n",
    "    Summary:\n",
    "        * Interpolate micasense image position using p1 pos and timestamp.\n",
    "        * Remove images that triggered outside p1 capture times\n",
    "        * Image Quality check\n",
    "        * Apply GPS/INS offset for gimbal 2\n",
    "        * Set primary channel to NIR\n",
    "        * Update Camera Accuracy settings for M300 RTK GNSS accuracy\n",
    "        * Set raster transform to export relative reflectance in orthomosaic\n",
    "        * Calibrate reflectance using both sun senors and panels\n",
    "        * Align images\n",
    "        * Build dense cloud\n",
    "        * Import RGB smoothed model (see proc_rgb)\n",
    "        * Build and export orthomosaic with raster transformed values (relative reflectance)\n",
    "    \"\"\"\n",
    "\n",
    "    chunk = doc.findChunk(dict_chunks[CHUNK_MULTISPEC])\n",
    "\n",
    "    target_crs = Metashape.CoordinateSystem(\"EPSG::\" + args.crs)\n",
    "\n",
    "    # Get image suffix of master camera\n",
    "    camera = chunk.cameras[0]\n",
    "    cam_master = camera.master.label.split('_')\n",
    "\n",
    "    # file naming assumption: IMG_xxxx_suffixNum\n",
    "    img_suffix_master = cam_master[2]\n",
    "    \n",
    "\n",
    "    #set P1_shift_vec to 0 if multionly is set\n",
    "    global P1_shift_vec \n",
    "    if args.multionly:\n",
    "        P1_shift_vec = np.array([0.0, 0.0, 0.0])\n",
    "\n",
    "    print(\"Interpolate Micasense position based on P1 with blockshift\" + str(P1_shift_vec))\n",
    "\n",
    "\n",
    "\n",
    "    # inputs: paths to MRK file for P1 position, Micasense image path, image suffix for master band images, target CRS\n",
    "    # returns output csv file with interpolated micasense positions\n",
    "    ret_micasense_pos(MRK_PATH, MICASENSE_PATH, img_suffix_master, args.crs,\n",
    "                      str(MICASENSE_CAM_CSV), P1_shift_vec)\n",
    "\n",
    "    # Load updated positions in the chunk\n",
    "    chunk.importReference(str(MICASENSE_CAM_CSV), format=Metashape.ReferenceFormatCSV, columns=\"nxyz\",\n",
    "                          delimiter=\",\", crs=target_crs, skip_rows=1,\n",
    "                          items=Metashape.ReferenceItemsCameras)\n",
    "    doc.save()\n",
    "\n",
    "    # ret_micasense_pos wrote Altitude = 0 (last column) for MicaSense images that triggered when P1 did not.\n",
    "    # Create a list of cameras with Altitude = 0\n",
    "    del_camera_names = list()\n",
    "\n",
    "    # Only look at altitude of master band images\n",
    "    for camera in chunk.cameras:\n",
    "        if not camera.label == camera.master.label:\n",
    "            continue\n",
    "        if not camera.reference.location:\n",
    "            continue\n",
    "        if camera.reference.location.z == 0:\n",
    "            del_camera_names.append(camera.label)\n",
    "\n",
    "    # Delete images outside of P1 capture times\n",
    "    print(\"Deleting MicaSense images that triggered outside P1 capture times\")\n",
    "    for camera in chunk.cameras:\n",
    "        # Only calibration images are in a group. The following line is necessary to avoid NoneType error on other images\n",
    "        if camera.group is not None:\n",
    "            if camera.group.label == 'Calibration images':\n",
    "                continue\n",
    "        if camera.label in del_camera_names:\n",
    "            chunk.remove(camera)\n",
    "\n",
    "    # Disable images outside of P1 capture times\n",
    "    # print(\"Disabling MicaSense images that triggered outside P1 capture times\")\n",
    "    # for camera in chunk.cameras:\n",
    "    #     # Only calibration images are in a group. The following line is necessary to avoid NoneType error on other images\n",
    "    #     if camera.group is not None:\n",
    "    #         if camera.group.label == 'Calibration images':\n",
    "    #             continue\n",
    "    #     if camera.label in del_camera_names:\n",
    "    #         camera.enabled = False\n",
    "            \n",
    "\n",
    "    # save project\n",
    "    doc.save()\n",
    "\n",
    "\n",
    "    # Set primary channel\n",
    "    #\n",
    "    # Get index of NIR band. Micasense Dual: NIR is sensors[9], and in RedEdge-M sensors[4]\n",
    "    if cam_model == 'RedEdge-M':\n",
    "        set_primary = \"NIR\"\n",
    "    elif cam_model == 'RedEdge-P':\n",
    "        set_primary = 'Panchro'\n",
    "    for s in chunk.sensors:\n",
    "        if s.label.find(set_primary) != -1:\n",
    "            print(\"Setting primary channel to \" + s.label)\n",
    "            chunk.primary_channel = s.layer_index\n",
    "            break\n",
    "\n",
    "\n",
    "    # GPS/INS offset for master sensor\n",
    "    #\n",
    "    print(\"Updating Micasense GPS offset\")\n",
    "    chunk.sensors[0].antenna.location_ref = Metashape.Vector(MS_GIMBAL2_OFFSET)\n",
    "\n",
    "    #\n",
    "    # Set Raster Transform to calculate reflectance\n",
    "    #\n",
    "    print(\"Updating Raster Transform for relative reflectance\")\n",
    "    raster_transform_formula = []\n",
    "    num_bands = len(chunk.sensors)\n",
    "    if cam_model == 'RedEdge-M':\n",
    "        for band in range(1, num_bands + 1):\n",
    "            raster_transform_formula.append(\"B\" + str(band) + \"/32768\")\n",
    "    elif cam_model == 'RedEdge-P':\n",
    "        # Skip Panchromatic band in multispec ortho.\n",
    "        # Panchro band: wavelength: 634.5 nm, Band 5 in RedEdge-P Dual and Band 3 in RedEdge-P.\n",
    "        if num_bands >= 10:\n",
    "            PANCHRO_BAND = 5\n",
    "        else:\n",
    "            PANCHRO_BAND = 3\n",
    "        for band in range(1, num_bands+1):\n",
    "            if band != PANCHRO_BAND:\n",
    "                raster_transform_formula.append(\"B\" + str(band) + \"/32768\")\n",
    "\n",
    "    chunk.raster_transform.formula = raster_transform_formula\n",
    "    chunk.raster_transform.calibrateRange()\n",
    "    chunk.raster_transform.enabled = True\n",
    "    doc.save()\n",
    "\n",
    "    #\n",
    "    # Estimate image quality and remove cameras with quality < threshold\n",
    "    #\n",
    "    if METASHAPE_V2_PLUS:\n",
    "        chunk.analyzeImages()\n",
    "    else:\n",
    "        chunk.analyzePhotos()\n",
    "    low_img_qual = []\n",
    "    low_img_qual = [camera.master for camera in chunk.cameras if (float(camera.meta[\"Image/Quality\"]) < 0.5)]\n",
    "    if low_img_qual:\n",
    "        print(\"Removing cameras with Image Quality < %.1f\" % 0.5)\n",
    "        chunk.remove(list(set(low_img_qual)))\n",
    "    doc.save()\n",
    "    #\n",
    "    #\n",
    "    # Calibrate Reflectance\n",
    "    #\n",
    "    chunk.calibrateReflectance(use_reflectance_panels=True, use_sun_sensor= args.sunsens)\n",
    "\n",
    "    #\n",
    "    # Align Photos\n",
    "    #\n",
    "    # change camera position accuracy to 0.1 m\n",
    "    chunk.camera_location_accuracy = Metashape.Vector((0.10, 0.10, 0.10))\n",
    "\n",
    "    # Downscale values per https://www.agisoft.com/forum/index.php?topic=11697.0\n",
    "    # Downscale: highest, high, medium, low, lowest: 0, 1, 2, 4, 8 # to be set below\n",
    "    # Quality:  High, Reference Preselection: Source\n",
    "    chunk.matchPhotos(downscale= quality3 , generic_preselection=False, reference_preselection=True,\n",
    "                      reference_preselection_mode=Metashape.ReferencePreselectionSource)\n",
    "    doc.save()\n",
    "    print(\"Aligning cameras\")\n",
    "    chunk.alignCameras()\n",
    "    doc.save()\n",
    "\n",
    "    # Gradual selection based on reprojection error\n",
    "    print(\"Gradual selection for reprojection error...\")\n",
    "    f = Metashape.TiePoints.Filter()\n",
    "    threshold = 0.5\n",
    "    f.init(chunk, criterion=Metashape.TiePoints.Filter.ReprojectionError)\n",
    "    f.removePoints(threshold)\n",
    "    doc.save()\n",
    "\n",
    "    #\n",
    "    # Optimise Cameras\n",
    "    #\n",
    "    print(\"Optimise alignment\")\n",
    "    chunk.optimizeCameras()\n",
    "    doc.save()\n",
    "\n",
    "    # copy bounding box from rgb chunk\n",
    "\n",
    "    copyBoundingBox(CHUNK_RGB, CHUNK_MULTISPEC)\n",
    "\n",
    "    #\n",
    "    # Build and export orthomosaic\n",
    "    #\n",
    "    if use_model:\n",
    "        # Import P1 model for use in orthorectification\n",
    "        smooth_val = DICT_SMOOTH_STRENGTH[args.smooth]\n",
    "        model_file = Path(proj_file).parent / (Path(proj_file).stem + \"_rgb_smooth_\" + str(smooth_val) + \".obj\")\n",
    "        chunk.importModel(path=str(model_file), crs=target_crs, format=Metashape.ModelFormatOBJ)\n",
    "\n",
    "        print(\"Build orthomosaic\")\n",
    "        chunk.buildOrthomosaic(surface_data=Metashape.DataSource.ModelData, refine_seamlines=True)\n",
    "        doc.save()\n",
    "\n",
    "    if use_dem:\n",
    "        dem_res_xy = 0.01  # Define the resolution for DEM\n",
    "        dem_file = Path(proj_file).parent / (Path(proj_file).stem + \"_dem_\" + str(dem_res_xy).split('.')[1] + \".tif\")\n",
    "        chunk.importRaster(path=dem_file, crs=target_crs, format=Metashape.ImageFormatTIFF)\n",
    "\n",
    "        print(\"Build orthomosaic\")\n",
    "        chunk.buildOrthomosaic(surface_data=Metashape.DataSource.ElevationData, refine_seamlines=True)\n",
    "        doc.save()\n",
    "\n",
    "    if chunk.orthomosaic:\n",
    "        # Set resolution to 5 cm\n",
    "        res_xy = 0.05\n",
    "\n",
    "        # if multispec/ folder does not exist in MICASENSE_PATH save in project directory\n",
    "        # else save ortho in multispec/level1_proc/\n",
    "        micasense_idx = MICASENSE_PATH.find(\"multispec\")\n",
    "        if micasense_idx == -1:\n",
    "            dir_path = Path(proj_file).parent\n",
    "            print(\"Cannot find \" + \"multispec/ folder. Saving ortho in \" + str(dir_path))\n",
    "        else:\n",
    "            # create multispec/level1_proc/ folder if it does not exist\n",
    "            dir_path = Path(MICASENSE_PATH[:micasense_idx + len(\"multispec\")]) / \"level1_proc\"\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # file naming format: <projname>_multispec_ortho_<res_in_m>.tif\n",
    "        ortho_file = dir_path / (\n",
    "                Path(proj_file).stem + \"_\" + \"multispec_ortho_\" + str(res_xy).split('.')[1] + \".tif\")\n",
    "\n",
    "        compression = Metashape.ImageCompression()\n",
    "        compression.tiff_compression = Metashape.ImageCompression.TiffCompressionLZW  # default on Metashape\n",
    "        compression.tiff_big = True\n",
    "        compression.tiff_tiled = True\n",
    "        compression.tiff_overviews = True\n",
    "\n",
    "        chunk.exportRaster(path=str(ortho_file), resolution_x=res_xy, resolution_y=res_xy,\n",
    "                           image_format=Metashape.ImageFormatTIFF,\n",
    "                           raster_transform=Metashape.RasterTransformValue,\n",
    "                           save_alpha=False, source_data=Metashape.OrthomosaicData, image_compression=compression)\n",
    "        print(\"Exported orthomosaic: \" + str(ortho_file))\n",
    "\n",
    "    # Export the processing report\n",
    "    report_path = dir_path / (\n",
    "                Path(proj_file).stem + \"_multispec_report.pdf\")\n",
    "    print(f\"Exporting processing report to {report_path}...\")\n",
    "    chunk.exportReport(path = str(report_path))\n",
    "    doc.save()\n",
    "        \n",
    "    print(\"Multispec chunk processing complete!\")\n",
    "\n",
    "\n",
    "# Write arguments to CSV file\n",
    "def write_arguments_to_csv():\n",
    "    global BASE_DIR\n",
    "    csv_file = os.path.join(BASE_DIR, \"arguments_log.csv\")\n",
    "    headers = [\"proj_path\"] + [arg for arg in vars(args).keys()]\n",
    "\n",
    "    # Collect argument values\n",
    "    row = [proj_file] + [str(getattr(args, arg)) for arg in vars(args).keys()]\n",
    "\n",
    "    # Check if the row already exists in the CSV file\n",
    "    if os.path.exists(csv_file):\n",
    "        with open(csv_file, mode='r', newline='') as file:\n",
    "            reader = csv.reader(file)\n",
    "            for existing_row in reader:\n",
    "                if existing_row == row:\n",
    "                    print(\"Row already exists in the CSV file. Skipping writing.\")\n",
    "                    return\n",
    "\n",
    "    # Write the row to the CSV file\n",
    "    with open(csv_file, mode='a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        if file.tell() == 0:\n",
    "            writer.writerow(headers)  # Write headers if file is empty\n",
    "        writer.writerow(row)\n",
    "        print(\"Arguments written to CSV file.\")\n",
    "\n",
    "# Resume processing\n",
    "def resume_proc():\n",
    "    # Process RGB chunk if multionly is not set\n",
    "    if not args.multionly:\n",
    "        proc_rgb()\n",
    "    # Process multispec chunk\n",
    "    proc_multispec()\n",
    "    print(\"End of script\")\n",
    "\n",
    "# Proceed to next project\n",
    "\n",
    "\n",
    "# -crs 2056 -multispec M:\\working_package_2\\2024_dronecampaign\\01_data\\dronetest\\MicasenseData\\fullset -rgb M:\\working_package_2\\2024_dronecampaign\\01_data\\dronetest\\P1Data\\DJI_202408080937_002_p1micasense60mtest \n",
    "\n",
    "\n",
    "############################################\n",
    "##  Main code\n",
    "############################################\n",
    "print(\"Script start\")\n",
    "\n",
    "# Parse arguments and initialise variables\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='Update camera positions in P1 and/or MicaSense chunks in Metashape project')\n",
    "parser.add_argument('-proj_path', help='path to Metashape project file')\n",
    "parser.add_argument('-date', help='Date of flight in YYYYMMDD format', required=True)\n",
    "parser.add_argument('-site', help='Site name', required=True)\n",
    "parser.add_argument('-crs',\n",
    "                    help='EPSG code for target projected CRS for micasense cameras. E.g: 7855 for GDA2020/MGA zone 55',\n",
    "                    required=True)\n",
    "parser.add_argument('-multispec', help='path to multispectral level0_raw folder with raw images')\n",
    "parser.add_argument('-rgb', help='path to RGB level0_raw folder that also has the MRK files')\n",
    "parser.add_argument('-smooth', help='Smoothing strength used to smooth RGB mesh low/med/high', default=\"low\")\n",
    "parser.add_argument('-drtk', help='If RGB coordinates to be blockshifted, file containing \\\n",
    "                                                  DRTK base station coordinates from field and AUSPOS', default=None)\n",
    "parser.add_argument('-sunsens', help='boolean to use sun sensor data for reflectance calibration', default=False)\n",
    "parser.add_argument('-test', help='boolean to make processing faster for debugging', default=False)\n",
    "parser.add_argument('-multionly', help='boolean to process multispec chunk only', default=False)\n",
    "\n",
    "global args\n",
    "args = parser.parse_args()\n",
    "global MRK_PATH, MICASENSE_PATH\n",
    "\n",
    "global doc\n",
    "# Metashape project\n",
    "if args.proj_path:\n",
    "    doc = Metashape.Document()\n",
    "    proj_file = args.proj_path\n",
    "    doc.open(proj_file, read_only=False)  # Open the document in editable mode\n",
    "else:    \n",
    "    doc = Metashape.Document()\n",
    "    proj_file = doc.path\n",
    "\n",
    "if doc is None:\n",
    "    print(\"Error: Metashape document object is not initialized.\")\n",
    "    \n",
    "# if Metashape project has not been saved\n",
    "# Set the base directory for the project\n",
    "# Create the project file path using site and date arguments if proj_path is not provided\n",
    "# if Metashape project has not been saved\n",
    "if proj_file == '':\n",
    "        site = args.site\n",
    "        date = args.date\n",
    "        proj_file = os.path.join(BASE_DIR, site, date, f\"{site}_{date}_metashape.psx\")\n",
    "        if not os.path.exists(proj_file):\n",
    "            doc.save(proj_file)\n",
    "        print(f\"Metashape project will be saved as {proj_file}\")\n",
    "        doc.open(proj_file, read_only=False)  # Open the document in editable mode\n",
    "        doc.save(proj_file)\n",
    "else:\n",
    "        proj_file = args.proj_path\n",
    "\n",
    "if args.rgb:\n",
    "    MRK_PATH = args.rgb\n",
    "else:\n",
    "    # Default is relative to project location: ../rgb/level0_raw/\n",
    "    MRK_PATH = Path(proj_file).parents[1] / \"rgb/level0_raw\"\n",
    "    if not MRK_PATH.is_dir():\n",
    "        sys.exit(\"%s directory does not exist. Check and input paths using -rgb \" % str(MRK_PATH))\n",
    "    else:\n",
    "        MRK_PATH = str(MRK_PATH)\n",
    "\n",
    "# TODO update when other sensors are used\n",
    "if args.multispec:\n",
    "    MICASENSE_PATH = args.multispec\n",
    "else:\n",
    "    # Default is relative to project location: ../multispec/level0_raw/\n",
    "    MICASENSE_PATH = Path(proj_file).parents[1] / \"multispec/level0_raw\"\n",
    "\n",
    "    if not MICASENSE_PATH.is_dir():\n",
    "        sys.exit(\"%s directory does not exist. Check and input paths using -multispec \" % str(MICASENSE_PATH))\n",
    "    else:\n",
    "        MICASENSE_PATH = str(MICASENSE_PATH)\n",
    "\n",
    "if args.drtk is not None:\n",
    "    DRTK_TXT_FILE = args.drtk\n",
    "    if not Path(DRTK_TXT_FILE).is_file():\n",
    "        sys.exit(\"%s file does not exist. Check and input correct path using -drtk option\" % str(DRTK_TXT_FILE))\n",
    "\n",
    "if args.smooth not in DICT_SMOOTH_STRENGTH:\n",
    "    sys.exit(\"Value for -smooth must be one of low, medium or high.\")\n",
    "\n",
    "# Set quality values for the downscale value in RGB and Multispec for testing\n",
    "if args.test:\n",
    "    quality1 = 4 #highest, high, medium, low, lowest: 0, 1, 2, 4, 8\n",
    "    quality2 = 8 #ultra, high, medium, low, lowest: 1, 2, 4, 8, 16\n",
    "    quality3 = 4 #highest, high, medium, low, lowest: 0, 1, 2, 4, 8\n",
    "    print(\"Test mode enabled: quality1 set to 4, quality2 set to 8, quality3 set to 4\")\n",
    "else:\n",
    "    quality1 = 1  #highest, high, medium, low, lowest: 0, 1, 2, 4, 8\n",
    "    quality2 = 4  #ultra, high, medium, low, lowest: 1, 2, 4, 8, 16\n",
    "    quality3 = 1  #highest, high, medium, low, lowest: 0, 1, 2, 4, 8\n",
    "    print(\"Default mode: quality1 set to 2, quality2 set to 2, quality3 set to 2\")\n",
    "\n",
    "# Export blockshifted P1 positions. Not used in script. Useful for debug or to restart parts of script following any issues.\n",
    "P1_CAM_CSV = Path(proj_file).parent / \"dbg_shifted_p1_pos.csv\"\n",
    "# By default save the CSV with updated MicaSense positions in the MicaSense folder. CSV used within script.\n",
    "MICASENSE_CAM_CSV = Path(proj_file).parent / \"interpolated_micasense_pos.csv\"\n",
    "\n",
    "##################\n",
    "# Add images\n",
    "##################\n",
    "# If the multionli argument is not set, add images to the project\n",
    "\n",
    "\n",
    "if not args.multionly:\n",
    "    # rgb\n",
    "    # Used to find chunks in proc_*\n",
    "    p1_images = find_files(MRK_PATH, (\".jpg\", \".jpeg\", \".tif\", \".tiff\"))\n",
    "    chunk = doc.addChunk()\n",
    "    chunk.label = CHUNK_RGB\n",
    "    chunk.addPhotos(p1_images) # , load_xmp_accuracy=True if you want to add accuracy from XMP\n",
    "\n",
    "    # Check that chunk is not empty and images are in default WGS84 CRS\n",
    "    if len(chunk.cameras) == 0:\n",
    "        sys.exit(\"Chunk rgb empty\")\n",
    "    # check chunk coordinate systems are default EPSG::4326\n",
    "    if \"EPSG::4326\" not in str(chunk.crs):\n",
    "            sys.exit(\"Chunk rgb: script expects images loaded to be in CRS WGS84 EPSG::4326\")\n",
    "\n",
    "    #\n",
    "    # multispec\n",
    "    #\n",
    "    micasense_images = find_files(MICASENSE_PATH, (\".jpg\", \".jpeg\", \".tif\", \".tiff\"))\n",
    "\n",
    "    chunk = doc.addChunk()\n",
    "    chunk.label = CHUNK_MULTISPEC\n",
    "    chunk.addPhotos(micasense_images)\n",
    "    doc.save()\n",
    "else:\n",
    "    # Used to find chunks in proc_*\n",
    "    check_chunk_list = [CHUNK_RGB, CHUNK_MULTISPEC]\n",
    "    dict_chunks = {}\n",
    "    for get_chunk in doc.chunks:\n",
    "        dict_chunks.update({get_chunk.label: get_chunk.key})\n",
    "\n",
    "    chunk = doc.findChunk(dict_chunks[CHUNK_RGB])\n",
    "    if not chunk:\n",
    "        sys.exit(\"Chunk rgb not found in the project\")\n",
    "    \n",
    "    chunk = doc.findChunk(dict_chunks[CHUNK_MULTISPEC])\n",
    "    if not chunk:\n",
    "        sys.exit(\"Chunk multispec not found in the project\")\n",
    "\n",
    "# Check that lever-arm offsets are non-zero:\n",
    "# As this script is for RGB and MS images captured simultaneously on dual gimbal, lever-arm offsets cannot be 0.\n",
    "#  Zenmuse P1\n",
    "if P1_GIMBAL1_OFFSET == 0:\n",
    "    err_msg = \"Lever-arm offset for P1 in dual gimbal mode cannot be 0. Update offset_dict and rerun_script.\"\n",
    "    Metashape.app.messageBox(err_msg)\n",
    "\n",
    "# MicaSense: get Camera Model from one of the images to check the lever-arm offsets for the relevant model\n",
    "micasense_images = find_files(MICASENSE_PATH, (\".jpg\", \".jpeg\", \".tif\", \".tiff\"))\n",
    "sample_img = open(micasense_images[0], 'rb')\n",
    "exif_tags = exifread.process_file(sample_img)\n",
    "cam_model = str(exif_tags.get('Image Model'))\n",
    "\n",
    "# HARDCODED number of bands.\n",
    "if len(chunk.sensors) >= 10:\n",
    "    # Dual sensor (RedEdge-MX Dual: 10, RedEdge-P Dual: 11)\n",
    "    # Dual sensor: If offsets are 0, exit with error.\n",
    "    if offset_dict[cam_model]['Dual'] == (0, 0, 0):\n",
    "        err_msg = \"Lever-arm offsets for \" + cam_model + \" Dual on gimbal 2 cannot be 0. Update offset_dict and rerun script.\"\n",
    "        Metashape.app.messageBox(err_msg)\n",
    "    else:\n",
    "        MS_GIMBAL2_OFFSET = offset_dict[cam_model]['Dual']\n",
    "else:\n",
    "    # RedEdge-MX or RedEdge-P (5-band or 6-band respectively): If offsets are 0, exit with error.\n",
    "    if offset_dict[cam_model]['Red'] == (0, 0, 0):\n",
    "        err_msg = \"Lever-arm offsets for \" + cam_model + \" Red on gimbal 2 cannot be 0. Update offset_dict and rerun script.\"\n",
    "        Metashape.app.messageBox(err_msg)\n",
    "    else:\n",
    "        MS_GIMBAL2_OFFSET = offset_dict[cam_model]['Red']\n",
    "\n",
    "\n",
    "# Used to find chunks in proc_*\n",
    "check_chunk_list = [CHUNK_RGB, CHUNK_MULTISPEC]\n",
    "dict_chunks = {}\n",
    "for get_chunk in doc.chunks:\n",
    "    dict_chunks.update({get_chunk.label: get_chunk.key})\n",
    "\n",
    "# Delete 'Chunk 1' that is created by default.\n",
    "if 'Chunk 1' in dict_chunks:\n",
    "    chunk = doc.findChunk(dict_chunks['Chunk 1'])\n",
    "    doc.remove(chunk)\n",
    "    doc.save()\n",
    "\n",
    "\n",
    "\n",
    "write_arguments_to_csv()\n",
    "\n",
    "\n",
    "# Open the Metashape document\n",
    "doc.open(proj_file, read_only=False)  # Open the document\n",
    "#\n",
    "# # Stop script here. User to click 'Resume Processing' once following steps are complete.\n",
    "# # see resume_proc() for processing steps.\n",
    "doc.save()\n",
    "print(\"Add images completed.\")\n",
    "print(\"###########################\")\n",
    "print(\"###########################\")\n",
    "print(\"###########################\")\n",
    "print(\"###########################\")\n",
    "print(\n",
    "    \"Step 1. In the Workspace pane, select multispec chunk. Select Tools-Calibrate Reflectance and 'Locate panels'. Press Cancel once the panels have been located.\")\n",
    "print(\n",
    "    \"Note: The csv of the calibration panel will have to be loaded if this is the first run on the machine. See the protocol for more information.\")\n",
    "print(\n",
    "    \"Step 2. In the Workspace pane under multispec chunk open Calibration images folder. Select and remove images not to be used for calibration.\")\n",
    "print(\"Step 3. Press the 'Show Masks' icon in the toolbar and inspect the masks on calibration images.\")\n",
    "print(\n",
    "    \"Complete Steps 1 to 3 and press 'Resume Processing' to continue. Reflectance calibration will be completed in the script.\")\n",
    "print(\"###########################\")\n",
    "print(\"###########################\")\n",
    "print(\"###########################\")\n",
    "print(\"###########################\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
